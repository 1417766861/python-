搜索文档树：
1. find和find_all方法：
搜索文档树，一般用得比较多的就是两个方法，一个是find，一个是find_all。find方法是找到第一个满足条件的标签后就立即返回，只返回一个元素。find_all方法是把所有满足条件的标签都选到，然后返回回去。使用这两个方法，最常用的用法是出入name以及attr参数找出符合要求的标签。

soup.find_all("a",attrs={"id":"link2"})
或者是直接传入属性的的名字作为关键字参数：

soup.find_all("a",id='link2')
2. select方法：
使用以上方法可以方便的找出元素。但有时候使用css选择器的方式可以更加的方便。使用css选择器的语法，应该使用select方法。以下列出几种常用的css选择器方法：

（1）通过标签名查找：
print(soup.select('a'))
（2）通过类名查找：
通过类名，则应该在类的前面加一个.。比如要查找class=sister的标签。示例代码如下：

print(soup.select('.sister'))
（3）通过id查找：
通过id查找，应该在id的名字前面加一个＃号。示例代码如下：

print(soup.select("#link1"))
（4）组合查找：
组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开：

print(soup.select("p #link1"))
直接子标签查找，则使用 > 分隔：

print(soup.select("head > title"))
（5）通过属性查找：
查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。示例代码如下：

print(soup.select('a[href="http://example.com/elsie"]'))
（6）获取内容
以上的 select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容。

soup = BeautifulSoup(html, 'lxml')
print type(soup.select('title'))
print soup.select('title')[0].get_text()

for title in soup.select('title'):
    print title.get_text()